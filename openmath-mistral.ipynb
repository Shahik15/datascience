{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73231,"databundleVersionId":8133715,"sourceType":"competition"},{"sourceId":7369493,"sourceType":"datasetVersion","datasetId":4281572},{"sourceId":8023365,"sourceType":"datasetVersion","datasetId":4728129}],"dockerImageVersionId":30674,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# credits:\n# https://www.kaggle.com/code/olyatsimboy/aimo-openmath-mistral-baseline\n# https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n# https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline","metadata":{"execution":{"iopub.status.busy":"2024-04-04T13:44:35.370565Z","iopub.execute_input":"2024-04-04T13:44:35.370923Z","iopub.status.idle":"2024-04-04T13:44:35.376016Z","shell.execute_reply.started":"2024-04-04T13:44:35.370892Z","shell.execute_reply":"2024-04-04T13:44:35.37498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport random\nfrom transformers import pipeline\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:23:14.625450Z","iopub.execute_input":"2024-04-18T01:23:14.626211Z","iopub.status.idle":"2024-04-18T01:23:51.357898Z","shell.execute_reply.started":"2024-04-18T01:23:14.626178Z","shell.execute_reply":"2024-04-18T01:23:51.356879Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-18 01:23:30.476015: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-18 01:23:30.476299: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-18 01:23:30.757764: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Zero-shot MMOS-DeepSeekMath-7B with self-consistency and generated code reasoning evaluation\n\nSelf-consistency is a modification of the standard greedy decoding in reasoning pipelines via sampling several diverse answers followed by aggregation, e.g., most common answer ([SC-CoT paper](https://arxiv.org/pdf/2203.11171.pdf)).\n\nIn this kernel, we will consider MMOS-DeepSeekMath-7B RL-tuned backbone; in my experiments, this model produces more consistent code reasoning and the code block execution will allow us to decrease arithmetic hallucinations.","metadata":{}},{"cell_type":"code","source":"!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq","metadata":{"papermill":{"duration":18.075198,"end_time":"2024-02-29T09:25:25.295954","exception":false,"start_time":"2024-02-29T09:25:07.220756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-18T01:23:58.097097Z","iopub.execute_input":"2024-04-18T01:23:58.098438Z","iopub.status.idle":"2024-04-18T01:24:37.655173Z","shell.execute_reply.started":"2024-04-18T01:23:58.098399Z","shell.execute_reply":"2024-04-18T01:24:37.653919Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    BitsAndBytesConfig, \n    AutoConfig,\n    set_seed\n)\n\nset_seed(42)\n\nMODEL_PATH = \"/kaggle/input/open-math-mistral\"\n\nquantization_config = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n    bnb_4bit_use_double_quant=True,\n)\n\nconfig = AutoConfig.from_pretrained(MODEL_PATH)\nconfig.gradient_checkpointing = True\n\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n#     quantization_config=quantization_config,\n    config=config\n)\npipeline= pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype='auto',\n    device_map='auto',\n\n)","metadata":{"papermill":{"duration":664.688061,"end_time":"2024-02-29T09:36:29.988515","exception":false,"start_time":"2024-02-29T09:25:25.300454","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-18T01:24:52.586025Z","iopub.execute_input":"2024-04-18T01:24:52.586889Z","iopub.status.idle":"2024-04-18T01:28:41.222476Z","shell.execute_reply.started":"2024-04-18T01:24:52.586777Z","shell.execute_reply":"2024-04-18T01:28:41.221312Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ec3f7a5259848f9a4b6490e17e5389b"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\ntorch.backends.cuda.enable_mem_efficient_sdp(False) # this script processes data, solves problems, handles exceptions","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:29:08.735300Z","iopub.execute_input":"2024-04-18T01:29:08.735665Z","iopub.status.idle":"2024-04-18T01:29:08.740059Z","shell.execute_reply.started":"2024-04-18T01:29:08.735638Z","shell.execute_reply":"2024-04-18T01:29:08.739118Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/ai-mathematical-olympiad-prize/train.csv\")\ntrain.head()\n\ntest = pd.read_csv(\"/kaggle/input/ai-mathematical-olympiad-prize/test.csv\")\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:29:11.646143Z","iopub.execute_input":"2024-04-18T01:29:11.646500Z","iopub.status.idle":"2024-04-18T01:29:11.684161Z","shell.execute_reply.started":"2024-04-18T01:29:11.646472Z","shell.execute_reply":"2024-04-18T01:29:11.683181Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       id                 problem\n0  000aaa          What is $1-1$?\n1  111bbb    What is $0\\times10$?\n2  222ccc  Solve $4+x=4$ for $x$.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>problem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000aaa</td>\n      <td>What is $1-1$?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>111bbb</td>\n      <td>What is $0\\times10$?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>222ccc</td>\n      <td>Solve $4+x=4$ for $x$.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"prompt = \"\"\"You are Math Professor, an exceptionally intelligent Professor tasked with solving intricate mathematical problems.\n\nMath Professor will be given a mathematical problem written in LaTeX, and will provide a precise answer, adhering to the following rules:\n- Math Professor guarantees a correct answer, always within the range of 0 to 999.\n- Answers will be concise and limited to a single number.\n- Math Professor will respond even when unsure or when the question is not fully understood.\n- Only the final result will be provided, no additional information.\n- The answer written in the \"Answer\" section must be concise and only include the final result.\n- Math Professor will always follow these rules.\n\n# Question\nLet $D(n)$ denote the number of ways of writing the positive integer $n$ as a product\\[n = f_1\\cdot f_2\\cdots f_k,\\]where $k\\ge1$, the $f_i$ are integers strictly greater than $1$, and the order in which the factors are listed matters (that is, two representations that differ only in the order of the factors are counted as distinct). For example, the number $6$ can be written as $6$, $2\\cdot 3$, and $3\\cdot2$, so $D(6) = 3$. What is $D(96)$? \n\n# Answer (only one number between 0 and 999)\n112\n\n{examples}\n\n\n# Question\n{question}\n\n# Answer (only one number between 0 and 999)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:29:19.727635Z","iopub.execute_input":"2024-04-18T01:29:19.728482Z","iopub.status.idle":"2024-04-18T01:29:19.733882Z","shell.execute_reply.started":"2024-04-18T01:29:19.728451Z","shell.execute_reply":"2024-04-18T01:29:19.732918Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def out(examples_df: pd.DataFrame | None , df, template):\n    submission = {\"id\": [], \"answer\": []}\n\n    examples = \"\"\n    if examples_df is not None and not examples_df.empty:\n        examples = []\n        for idx, row in examples_df.iterrows():\n            examples.append(\"# Question\")\n            examples.append(str(row[\"problem\"]))\n            examples.append(\"# Answer (only one number between 0 and 999)\")\n            examples.append(str(row[\"answer\"]))\n        examples = \"\\n\".join(examples)\n    \n    for idx, row in tqdm(df.iterrows()):\n        try:\n            model_input = template.format(examples=examples, question=row[\"problem\"])\n            response = pipeline(model_input, do_sample=False, max_new_tokens=3)\n            output = response[0]['generated_text']\n            \n            output = int(re.sub(r\"[^0-9]\", \"\", output))\n\n            submission[\"id\"].append(row[\"id\"])\n            submission[\"answer\"].append(output)\n            torch.cuda.empty_cache()\n            gc.collect()\n        except Exception as e:\n            print(f\"Exception: {e}\")\n            submission[\"id\"].append(row[\"id\"])\n            submission[\"answer\"].append(random.randint(0, 999))\n            \n    submission_df = pd.DataFrame(submission)\n    submission_df[\"answer\"] = submission_df[\"answer\"].apply(lambda x: abs(x) % 1000)\n    return submission_df","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:29:24.163853Z","iopub.execute_input":"2024-04-18T01:29:24.164467Z","iopub.status.idle":"2024-04-18T01:29:24.175111Z","shell.execute_reply.started":"2024-04-18T01:29:24.164436Z","shell.execute_reply":"2024-04-18T01:29:24.174100Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"linkcode\nThe out function generates submissions based on provided examples, a main DataFrame, a template, and a machine learning model. Here's how it works:\n\nInput Parameters:\n\nmodel: The machine learning model used to generate answers.\nexamples_df: A DataFrame containing example questions and answers (optional).\ndf: The main DataFrame containing questions.\ntemplate: A template string used to format questions and generate answers.\nExample Formatting:\n\nIf examples_df is provided and not empty, the function formats it into a string.\nSubmission Generation:\n\nFor each row in the main DataFrame (df):\nIt attempts to generate an answer using the provided template and model.\nIf successful, it appends the answer to the submission dictionary.\nIf an exception occurs during answer generation, it prints the exception and adds a random answer instead.\nFinal Submission DataFrame:\n\nThe function converts the submission dictionary into a DataFrame.\nIt ensures that the answer values are within the range of 0 to 999.\nOutput:\n\nThe function returns the submission DataFrame containing question IDs and their respective answers.","metadata":{}},{"cell_type":"code","source":"output = out(train, test, prompt)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-04-18T01:29:29.636920Z","iopub.execute_input":"2024-04-18T01:29:29.637910Z","iopub.status.idle":"2024-04-18T01:29:55.540093Z","shell.execute_reply.started":"2024-04-18T01:29:29.637876Z","shell.execute_reply":"2024-04-18T01:29:55.539042Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n1it [00:10, 10.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Exception: name 'gc' is not defined\n","output_type":"stream"},{"name":"stderr","text":"2it [00:18,  8.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Exception: name 'gc' is not defined\n","output_type":"stream"},{"name":"stderr","text":"3it [00:25,  8.63s/it]","output_type":"stream"},{"name":"stdout","text":"Exception: name 'gc' is not defined\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"       id  answer\n0  000aaa     990\n1  000aaa     654\n2  111bbb     990\n3  111bbb     114\n4  222ccc     990\n5  222ccc      25","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000aaa</td>\n      <td>990</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000aaa</td>\n      <td>654</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>111bbb</td>\n      <td>990</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>111bbb</td>\n      <td>114</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>222ccc</td>\n      <td>990</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>222ccc</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}